{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Основы PyTorch\n",
    "\n",
    "## Математические методы анализа текстов, 2020\n",
    "\n",
    "## Попов Артём\n",
    "\n",
    "В данном ноутбуке рассмотрены базовые составляющие библиотеки Pytorch: тензорные вычисления и автоматическое дифференцирование.\n",
    "\n",
    "Официальные туториалы pytorch по этим темам:\n",
    "\n",
    "* [What is pytorch?](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py)\n",
    "\n",
    "* [Autograd: automatic differentiation](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тензоры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В интерфейсе базовых операций Tensor почти не отличается от np.array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.1118e-04, 1.7444e+28, 7.3909e+22],\n",
       "        [4.5828e+30, 3.2483e+33, 1.9690e-19],\n",
       "        [6.8589e+22, 1.3340e+31, 1.1708e-19],\n",
       "        [7.2128e+22, 9.2216e+29, 7.5546e+31],\n",
       "        [1.6932e+22, 3.0728e+32, 2.9514e+29]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5.],\n",
       "        [5., 5., 5.],\n",
       "        [5., 5., 5.],\n",
       "        [5., 5., 5.],\n",
       "        [5., 5., 5.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3508, -0.8261, -1.0995],\n",
       "        [-1.4397,  0.3349,  0.8214],\n",
       "        [ 0.4103, -0.5048, -0.3590],\n",
       "        [ 0.3913, -0.3321,  1.1700],\n",
       "        [ 0.0361, -0.6539,  0.3596]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(5, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3508, -1.4397,  0.4103,  0.3913,  0.0361],\n",
      "        [-0.8261,  0.3349, -0.5048, -0.3321, -0.6539],\n",
      "        [-1.0995,  0.8214, -0.3590,  1.1700,  0.3596]])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.transpose(0, 1))\n",
    "print(x.shape)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3508, -1.4397,  0.4103,  0.3913,  0.0361],\n",
      "        [-0.8261,  0.3349, -0.5048, -0.3321, -0.6539],\n",
      "        [-1.0995,  0.8214, -0.3590,  1.1700,  0.3596]])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(torch.transpose(x, 0, 1))\n",
    "print(x.shape)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сложение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6164, -0.8128, -0.4678],\n",
      "        [-1.2136,  0.5285,  1.5376],\n",
      "        [ 0.9532,  0.4519,  0.3358],\n",
      "        [ 0.4025,  0.1224,  1.9493],\n",
      "        [ 0.3197, -0.2858,  1.0654]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Операции с _ — inplace операции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6164, -0.8128, -0.4678],\n",
      "        [-1.2136,  0.5285,  1.5376],\n",
      "        [ 0.9532,  0.4519,  0.3358],\n",
      "        [ 0.4025,  0.1224,  1.9493],\n",
      "        [ 0.3197, -0.2858,  1.0654]])\n",
      "tensor([[ 1.6164, -0.8128, -0.4678],\n",
      "        [-1.2136,  0.5285,  1.5376],\n",
      "        [ 0.9532,  0.4519,  0.3358],\n",
      "        [ 0.4025,  0.1224,  1.9493],\n",
      "        [ 0.3197, -0.2858,  1.0654]])\n",
      "tensor([[ 1.6164, -0.8128, -0.4678],\n",
      "        [-1.2136,  0.5285,  1.5376],\n",
      "        [ 0.9532,  0.4519,  0.3358],\n",
      "        [ 0.4025,  0.1224,  1.9493],\n",
      "        [ 0.3197, -0.2858,  1.0654]])\n"
     ]
    }
   ],
   "source": [
    "print(x.add(y))\n",
    "print(x.add_(y))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матричное умножение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(5, 3) \n",
    "b = torch.randn(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0138,  0.8269,  0.4714, -1.4878],\n",
       "        [ 2.8575, -2.8601, -0.3185,  0.3229],\n",
       "        [ 2.7084, -2.6616,  0.7172,  0.3635],\n",
       "        [ 2.2819, -2.0405,  0.4465,  1.7203],\n",
       "        [ 0.7335, -0.6931, -1.2588,  0.6825]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0138,  0.8269,  0.4714, -1.4878],\n",
      "        [ 2.8575, -2.8601, -0.3185,  0.3229],\n",
      "        [ 2.7084, -2.6616,  0.7172,  0.3635],\n",
      "        [ 2.2819, -2.0405,  0.4465,  1.7203],\n",
      "        [ 0.7335, -0.6931, -1.2588,  0.6825]])\n",
      "tensor([[-1.0138,  0.8269,  0.4714, -1.4878],\n",
      "        [ 2.8575, -2.8601, -0.3185,  0.3229],\n",
      "        [ 2.7084, -2.6616,  0.7172,  0.3635],\n",
      "        [ 2.2819, -2.0405,  0.4465,  1.7203],\n",
      "        [ 0.7335, -0.6931, -1.2588,  0.6825]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.mm(a,b))\n",
    "print(a.mm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменение размера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перевод в numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a += 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перевод на GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000, -1.5303, -2.1708, -1.2409],\n",
       "        [ 1.1143,  0.1901,  0.4472,  0.0644],\n",
       "        [-0.3072,  0.8485,  0.6883, -1.4604],\n",
       "        [ 0.1533,  0.1766,  0.4999,  0.5292]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(2, 3).to(0)\n",
    "y = torch.ones(2, 3).to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на параметр device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Графы вычислений, автоматическое дифференцирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Раньше для построения графов вычислений нужно было использовать специальную сущность — Variable.\n",
    "\n",
    "Например, это делалось так:\n",
    "\n",
    "```\n",
    "from torch.autograd import Variable\n",
    "\n",
    "x = Variable(torch.ones(2, 2), requires_grad=True)\n",
    "```\n",
    "\n",
    "Сейчас это не нужно, вся функциональность Variable помещена в Tensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обозначим, что для x нужно считать градиенты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((3, 3), requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производя операции с переменными, по которым нужно считать градиенты, мы конструируем граф вычислений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В каждой переменной есть информация о том, как именно она была получена при проходе вперёд:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddBackward0 at 0x2463994ad48>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y * y * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MulBackward0 at 0x24639af73c8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MeanBackward0 at 0x24639d8c508>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16.1721, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проход назад выполняется с помощью вызова метода .backward():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После выполнения .backward() у листовых переменных графа (у которых .requires_grad = True) появится атрибут .grad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1.4884, 1.5250, 1.4889],\n",
       "         [1.6359, 1.3703, 1.6422],\n",
       "         [1.4685, 1.4105, 1.8461]]),\n",
       " None,\n",
       " None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad, y.grad, z.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно считать граф для не листовых переменных, для этого необходимо воспользоваться методом .retain_graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((3, 3), requires_grad=True)\n",
    "y = x + 2\n",
    "y.retain_grad()\n",
    "\n",
    "z = torch.mean(y)\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1111, 0.1111, 0.1111],\n",
       "        [0.1111, 0.1111, 0.1111],\n",
       "        [0.1111, 0.1111, 0.1111]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inplace операции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4648, 0.0733, 0.8782],\n",
       "        [0.6297, 0.2181, 0.1124],\n",
       "        [0.3685, 0.6645, 0.6081]], requires_grad=True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((3, 3), requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a leaf Variable that requires grad is being used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-9c06ae6cc4f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: a leaf Variable that requires grad is being used in an in-place operation."
     ]
    }
   ],
   "source": [
    "x += 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inplace операции заменяем на not-inplace с помощью введения дополнительных промежуточных переменных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно помнить про работу присваивания в языке Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((3, 3), requires_grad=True)\n",
    "x = x + 2 # x += 2\n",
    "x.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно строить граф вычислений с помощью циклов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((3, 3), requires_grad=True)\n",
    "y = x\n",
    "\n",
    "while x.data.norm() < 1000:\n",
    "    x = x * 2\n",
    "\n",
    "\n",
    "z = x.mean()\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой будет результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[56.8889, 56.8889, 56.8889],\n",
       "        [56.8889, 56.8889, 56.8889],\n",
       "        [56.8889, 56.8889, 56.8889]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.к. y указывает на самый первый x, а x на самый последний (для которого не вызывался .retain_graph)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно вычислять производную по направлению:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000e+00, 2.0000e+00, 2.0000e-04])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([1, 2, 3])\n",
    "x.requires_grad = True\n",
    "\n",
    "y = x * 2\n",
    "\n",
    "gradients = torch.FloatTensor([0, 1, 0.0001])\n",
    "y.backward(gradients)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиенты накапливаются! Т.е. если несколько раз вызвать .backward, значения в .grad будут суммироваться:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6667, 0.6667, 0.6667])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([1, 2, 3])\n",
    "x.requires_grad = True\n",
    "\n",
    "y = (x * 2).mean()\n",
    "y.backward()\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.3333, 1.3333, 1.3333])\n"
     ]
    }
   ],
   "source": [
    "y = (x * 2).mean()\n",
    "y.backward()\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью специального мененджера контекста, можно не считать градиенты при вычислениях (например, для ускорения работы):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([1, 2, 3])\n",
    "x.requires_grad = True\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = x * 2\n",
    "    \n",
    "y.grad_fn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
